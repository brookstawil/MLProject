{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3 - Autism\n",
    "\n",
    "This dataset provides 20 attributes to help determine if an adult could be on the autistic spectrum or have ASD. The data provided is based upon autism screening of adults in contrast to most other datasets based on behavior traits. In the dataset, 10 behavioral and 10 individual characteristics are provided.\n",
    "https://archive.ics.uci.edu/ml/datasets/Autism+Screening+Adult\n",
    "\n",
    "#### Problem\n",
    "Our goal is to create a classifier, that can diagnose autism based on the answers to certain questions and physical characteristics. This is a classification problem and very much mirrors our hypothetical situations of diagnosing cancer that we discuss in class. Except our features are more based around psychological evaluation and not physical traits and attributes of a physical ailment.\n",
    "\n",
    "#### Extending the problem\n",
    "Out of all of the datasets, this one has the most social impact, and the creation of such an algorithm is most likely already the subject of study in various academic realms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "The dataset is laid out in a .arff file and needs to be loaded properly so that we can use it. Fortunately, Scipy has a function to hanle this.\n",
    "\n",
    "Some features, like the answers to test questions, are binary. While others like age are intgers, and others are strings. \n",
    "\n",
    "Some features are translated into binary features. Gender is taken as a binary feature, with 'False' being taken as male and 'True' being taken female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "\n",
    "file = './Data/Autism/Autism-Adult-Data.arff'\n",
    "filedata, metadata = arff.loadarff(file)\n",
    "\n",
    "'''\n",
    "print (metadata)\n",
    "print (filedata[0])\n",
    "'''\n",
    "\n",
    "# Data is not properly typed and needs to be converted\n",
    "data = [[None for _ in range(len(filedata[0]))] for _ in range(len(filedata))]\n",
    "for i in range(len(filedata)):\n",
    "    for j in range(len(filedata[i])):\n",
    "        # Binary features, Answer Scores\n",
    "        if (j < 10):\n",
    "            if (filedata[i][j] == b'1'):\n",
    "                data[i][j] = True\n",
    "            else:\n",
    "                data[i][j] = False\n",
    "        # Integer Features, Age feature, Screen Score\n",
    "        elif (j == 10 or j == 17):\n",
    "            data[i][j] = filedata[i][j]\n",
    "        # Gender Feature to binary\n",
    "        elif (j == 11):\n",
    "            if (filedata[i][j] == 'm'):\n",
    "                data[i][j] = False\n",
    "            else:\n",
    "                data[i][j] = True\n",
    "        # String features, Ethnicity, Country of Origin (enclossed in '' within the string), 18 or older, relation\n",
    "        elif (j == 12 or j == 15 or j == 18 or j == 19):\n",
    "            data[i][j] = filedata[i][j].decode(\"utf-8\")\n",
    "        # Jaundice, Family Member with a PDD\n",
    "        elif (j == 13 or j == 14 or j == 16):\n",
    "            if (filedata[i][j] == b'yes'):\n",
    "                data[i][j] = True\n",
    "            else:\n",
    "                data[i][j] = False\n",
    "        # Final classification\n",
    "        elif (j == 20):\n",
    "            if (filedata[i][j] == b'YES'):\n",
    "                data[i][j] = True\n",
    "            else:\n",
    "                data[i][j] = False\n",
    "\n",
    "    # Make the row into a numpy array\n",
    "    data[i] = np.array(data[i])\n",
    "\n",
    "# Make the whole dataset into a numpy array\n",
    "data = np.array(data)\n",
    "\n",
    "# Transpose so that features are along the rows and data points are along the columns\n",
    "data = data.transpose()\n",
    "\n",
    "# Extract the label from the data\n",
    "labels = data[20:,:]\n",
    "data = data[:20,:]\n",
    "\n",
    "# data is now the features matrix column wise and the labels are separated into a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Dataset\n",
    "With the data properly loaded, we need to look over our features and potentially clean or adjust the data.\n",
    "\n",
    "In our dataset, there is an \"18 years or older\" feature, which is the same for every datapoint, a hold over from what can be assumed to be related to a legal obligation of an adult's consent to colllect the data. Thus we can cut that feature out entirely from the beginning.\n",
    "\n",
    "Additionally, we can elect to exclude other features which we are not interested in including in our analysis such as .\n",
    "\n",
    "We can cut these out of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing our Cleaned Data\n",
    "\n",
    "This dataset required the most adjustment so that it can be used for the purposes of this project, mostly stemming from the use of an arff file for storing and distributing the data. In addition, not every feature was relevnant as mentioned above. But now we can attempt to build a classifier around our data, to classify whether given ADS evaluation answers, and other factors, would lead to an ASD diagnosis. These are the 3 methods that will be used, along with the group member responsible for that method:\n",
    "\n",
    "- Classification Method 1 - Brooks Tawil\n",
    "- Naive Bayes - Jack Chiu\n",
    "- Classification Method 3 - Gavin Mckim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  3  with average accuracy =  0.98523\n",
      "Accuracy for each fold:  [0.99505, 0.985149, 0.97549]\n",
      "k =  5  with average accuracy =  0.986857\n",
      "Accuracy for each fold:  [1.0, 0.983471, 0.975207, 0.991736, 0.983871]\n",
      "k =  7  with average accuracy =  0.993355\n",
      "Accuracy for each fold:  [1.0, 1.0, 1.0, 0.976744, 0.988372, 0.988372, 1.0]\n",
      "k =  9  with average accuracy =  0.991708\n",
      "Accuracy for each fold:  [1.0, 1.0, 0.970149, 1.0, 0.970149, 1.0, 1.0, 0.985075, 1.0]\n",
      "k =  11  with average accuracy =  0.996694\n",
      "Accuracy for each fold:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.981818, 1.0, 0.981818, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import arff as ARFF\n",
    "\n",
    "def uNiQuE(vec):\n",
    "    popCtr = 0\n",
    "    for p in vec:\n",
    "        if p in vec[:popCtr]:\n",
    "            vec = np.delete(vec, popCtr, 0)\n",
    "            popCtr -= 1\n",
    "        popCtr += 1\n",
    "        \n",
    "    return vec\n",
    "\n",
    "def preProcess(data):\n",
    "    i = 0\n",
    "    for q in range(len(data)):\n",
    "        if None in data[i] or data[i,10] == 383:\n",
    "            data = np.delete(data, i, 0)\n",
    "            i -= 1        \n",
    "        i += 1\n",
    "\n",
    "        for j in range(len(data[i-1])):\n",
    "            if type(data[i-1,j]) == str:\n",
    "                data[i-1,j] = data[i-1,j].lower()\n",
    "    \n",
    "    labels = data[:,-1]\n",
    "    data = np.delete(data, -1, 1)\n",
    "    \n",
    "    ethnicities = uNiQuE(data[:,12])\n",
    "    countries = uNiQuE(data[:,15])\n",
    "    completed = uNiQuE(data[:,-1])\n",
    "    yesNo = np.array(['no', 'yes'])\n",
    "    ageVec = np.arange(20,80, 10)\n",
    "    for i in range(len(data)):\n",
    "        data[i,:10] = data[i,:10].astype(int)\n",
    "        \n",
    "        tempInd = np.where(ageVec > int(data[i,10]))\n",
    "        data[i,10] = int(tempInd[0][0])\n",
    "    \n",
    "        if data[i,11] == 'm':\n",
    "            data[i,11] = 1\n",
    "        else:\n",
    "            data[i,11] = 0\n",
    "        tempInd = np.where(ethnicities == data[i,12])\n",
    "        data[i,12] = int(tempInd[0])\n",
    "        \n",
    "        tempInd = np.where(yesNo == data[i,13])\n",
    "        data[i,13] = int(tempInd[0])\n",
    "        tempInd = np.where(yesNo == data[i,14])\n",
    "        data[i,14] = int(tempInd[0])\n",
    "        \n",
    "        tempInd = np.where(countries == data[i,15])\n",
    "        data[i,15] = int(tempInd[0])\n",
    "        \n",
    "        tempInd = np.where(yesNo == data[i,16])\n",
    "        data[i,16] = int(tempInd[0])\n",
    "        \n",
    "        data[i,17] = int(data[i,17])\n",
    "        \n",
    "        data[i,18] = 1\n",
    "        \n",
    "        tempInd =  np.where(completed==data[i,19])\n",
    "        data[i,19] = int(tempInd[0])\n",
    "        \n",
    "        labels[i] = int(labels[i] == 'yes')\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "def kFold(data, labels, kFolds, typ = 'naive', k = 7):\n",
    "    #shuffle\n",
    "    inds = np.random.choice(np.arange(len(data)), len(data))\n",
    "    data[:] = data[inds]\n",
    "    labels[:] = labels[inds]\n",
    "\n",
    "    startInd = 0\n",
    "    stepSize = int(len(data)/kFolds)\n",
    "    max10 = max(data[:,10])\n",
    "    max12 = max(data[:,12])\n",
    "    max15 = max(data[:,15])\n",
    "    max17 = max(data[:,17])\n",
    "    max19 = max(data[:,19])\n",
    "    Errs = []\n",
    "    for i in range(kFolds):\n",
    "        if i != kFolds-1:\n",
    "            testData = data[startInd:startInd+stepSize]\n",
    "            testLabels = labels[startInd:startInd+stepSize]\n",
    "            trainingData = data[:startInd]\n",
    "            trainingData = np.concatenate((trainingData, data[startInd+stepSize:]))\n",
    "            trainingLabels = labels[:startInd]\n",
    "            trainingLabels = np.concatenate((trainingLabels,labels[startInd+stepSize:]))\n",
    "        else:\n",
    "            testData = data[startInd:]\n",
    "            testLabels = labels[startInd:]\n",
    "            trainingData = data[:startInd]\n",
    "            trainingLabels = labels[:startInd]\n",
    "        startInd += stepSize      \n",
    "        if typ == 'kNN':\n",
    "            trainingData[:,10] = trainingData[:,10]/max10\n",
    "            trainingData[:,12] = trainingData[:,12]/max12\n",
    "            trainingData[:,15] = trainingData[:,15]/max15\n",
    "            trainingData[:,17] = trainingData[:,17]/max17\n",
    "            trainingData[:,19] = trainingData[:,19]/max19\n",
    "            testData[:,10] = testData[:,10]/max10\n",
    "            testData[:,12] = testData[:,12]/max12\n",
    "            testData[:,15] = testData[:,15]/max15\n",
    "            testData[:,17] = testData[:,17]/max17\n",
    "            testData[:,19] = testData[:,19]/max19\n",
    "            temp = calcErr(trainingData, trainingLabels, testData, testLabels, k)\n",
    "        elif typ == 'naive':\n",
    "            temp = calcErrNaive(trainingData, trainingLabels, testData, testLabels)\n",
    "        \n",
    "        Errs.append(temp)\n",
    "    \n",
    "    return Errs\n",
    "        \n",
    "def trainNaive(data, labels):\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    prior = np.array([counts[0], counts[1]])\n",
    "    prior = (prior+0.0)/len(data)\n",
    "    conditional = np.zeros((2, len(data[0]), 60))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            conditional[labels[i], j, data[i,j]] += 1\n",
    "            \n",
    "    for i in range(len(conditional)):\n",
    "        for j in range(len(conditional[0])):\n",
    "            sumCondition = sum(conditional[0,j]) + sum(conditional[1,j])\n",
    "            for k in range(len(conditional[0,j])):\n",
    "                conditional[i,j,k] = conditional[i,j,k]/sumCondition\n",
    "    \n",
    "    return prior, conditional, unique\n",
    "\n",
    "def testNaive(prior, conditional, unique, sample):\n",
    "    prob = np.array([prior[0],prior[1]])\n",
    "    for i in range(len(sample)):\n",
    "        prob[0] = prob[0] * conditional[0,i,sample[i]]\n",
    "        prob[1] = prob[1] * conditional[1,i,sample[i]]\n",
    "    \n",
    "    if prob[0] >= prob[1]:\n",
    "        return unique[0]\n",
    "        \n",
    "    return unique[1]\n",
    "        \n",
    "def calcErrNaive(trainingData, trainingLabels, testData, testLabels):\n",
    "    errs = 0\n",
    "    prior, conditional, unique = trainNaive(trainingData, trainingLabels)\n",
    "    for i in range(len(testData)):\n",
    "        prediction = testNaive(prior, conditional, unique, testData[i])\n",
    "        errs += int(prediction != testLabels[i])\n",
    "    \n",
    "    return np.round(1-errs/len(testLabels), 6)\n",
    "\n",
    "#file = 'Autism-Adult-Data.arff'\n",
    "dataset = ARFF.load(open(file))\n",
    "DATA = np.array(dataset['data'])    \n",
    "DATA, LABELS = preProcess(DATA)\n",
    "inds = np.random.choice(np.arange(len(DATA)), len(DATA))\n",
    "DATA[:] = DATA[inds]\n",
    "LABELS[:] = LABELS[inds]\n",
    "for i in np.arange(3,13,2):\n",
    "    kErrs = kFold(DATA, LABELS, i, typ = 'naive')\n",
    "    print('k = ', i, ' with average accuracy = ' , np.average(kErrs).round(6))\n",
    "    print('Accuracy for each fold: ', kErrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes was created to classify from the data whether the individual would potentially have Autism. Evidently, from running the classifier with k-fold cross validation over various k values, the accuracy of the classifier was high $\\geq 98\\%$. It can be said that there is a strong correlation between the collected data and whether an individual had autism or not based on the Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
