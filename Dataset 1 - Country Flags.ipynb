{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 - Country Flags\n",
    "The dataset below provides different information of a country in order to predict potentially what the majority religion is. This falls more in line with a clustering problem, whereby flags are clustered into groups.\n",
    "https://archive.ics.uci.edu/ml/datasets/Flags?fbclid=IwAR3cI_9sS9XxKBJ-RPXEIAPBOS3QDqkS7qYxicM6F_TiJB--5P8r1Tt6Lxk\n",
    "\n",
    "#### Problem\n",
    "For this problem we contruct a classifier that will take in various attributes about a country's flag, an attempt to classify the majority religion of the country.\n",
    "\n",
    "#### Extending the problem\n",
    "With mre time and knowledge we could use more advanced ML algorithms to analyze this dataset. But in particiular, a more extensive knowledge in feature engineering would allow us to create our own features. The dataset is not insanly large, ~ 200 countries, so it is entirely within the realm of possibility to make our own features if we had more time and experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "Source Information\n",
    "   -- Creators: Collected primarily from the \"Collins Gem Guide to Flags\":\n",
    "      Collins Publishers (1986).\n",
    "   -- Donor: Richard S. Forsyth \n",
    "             8 Grosvenor Avenue\n",
    "             Mapperley Park\n",
    "             Nottingham NG3 5DX\n",
    "             0602-621676\n",
    "   -- Date: 5/15/1990\n",
    "   \n",
    "Number of Instances: 194\n",
    "\n",
    "Number of attributes: 30 (overall)\n",
    "\n",
    "Attribute Information:\n",
    "   1. name\tName of the country concerned\n",
    "   2. landmass\t1=N.America, 2=S.America, 3=Europe, 4=Africa, 4=Asia, 6=Oceania\n",
    "   3. zone\tGeographic quadrant, based on Greenwich and the Equator 1=NE, 2=SE, 3=SW, 4=NW\n",
    "   4. area\tin thousands of square km\n",
    "   5. population in round millions\n",
    "   6. language 1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic, 9=Japanese/Turkish/Finnish/Magyar, 10=Others\n",
    "   7. religion 0=Catholic, 1=Other Christian, 2=Muslim, 3=Buddhist, 4=Hindu, 5=Ethnic, 6=Marxist, 7=Others\n",
    "   8. bars     Number of vertical bars in the flag\n",
    "   9. stripes  Number of horizontal stripes in the flag\n",
    "  10. colours  Number of different colours in the flag\n",
    "  11. red      0 if red absent, 1 if red present in the flag\n",
    "  12. green    same for green\n",
    "  13. blue     same for blue\n",
    "  14. gold     same for gold (also yellow)\n",
    "  15. white    same for white\n",
    "  16. black    same for black\n",
    "  17. orange   same for orange (also brown)\n",
    "  18. mainhue  predominant colour in the flag (tie-breaks decided by taking the topmost hue, if that fails then the most central hue,and if that fails the leftmost hue)\n",
    "  19. circles  Number of circles in the flag\n",
    "  20. crosses  Number of (upright) crosses\n",
    "  21. saltires Number of diagonal crosses\n",
    "  22. quarters Number of quartered sections\n",
    "  23. sunstars Number of sun or star symbols\n",
    "  24. crescent 1 if a crescent moon symbol present, else 0\n",
    "  25. triangle 1 if any triangles present, 0 otherwise\n",
    "  26. icon     1 if an inanimate image present (e.g., a boat), otherwise 0\n",
    "  27. animate  1 if an animate image (e.g., an eagle, a tree, a human hand) present, 0 otherwise\n",
    "  28. text     1 if any letters or writing on the flag (e.g., a motto or slogan), 0 otherwise\n",
    "  29. topleft  colour in the top-left corner (moving right to decide tie-breaks)\n",
    "  30. botright Colour in the bottom-left corner (moving left to decide tie-breaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "This dataset is stored on a single csv file across all of the features. Numpy can easily load in these values int oa matrix so that we can use it in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 194)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "filedata = np.genfromtxt('./data/CountryFlags/flag.data', dtype=None, delimiter=',', encoding='utf-8')\n",
    "\n",
    "data = [[None for _ in range(len(filedata[0]))] for _ in range(len(filedata))]\n",
    "\n",
    "# Data is stored as mostly integers, but these correspond to a string in the data description, stored in these lists \n",
    "landmass = [None, 'N.America', 'S.America', 'Europe', 'Africa', 'Asia', 'Oceania']\n",
    "quadrant = [None, 'NE', 'SE', 'SW', 'NW']\n",
    "languages = [None, 'English', 'Spanish', 'French', 'German', 'Slavic', 'Other Indo-European', 'Chinese', 'Arabic', 'Japanese/Turkish/Finnish/Magyar', 'Others']\n",
    "religions = ['Catholic', 'Other Christian', 'Muslim', 'Buddhist', 'Hindu', 'Ethnic', 'Marxist', 'Others']\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        # Country Name\n",
    "        if (j == 0):\n",
    "            data[i][j] = str(filedata[i][j])\n",
    "        # Landmass\n",
    "        elif (j == 1):\n",
    "            data[i][j] = landmass[filedata[i][j]]\n",
    "        elif (j  == 2):\n",
    "            data[i][j] = quadrant[filedata[i][j]]\n",
    "        elif (j  == 5):\n",
    "            data[i][j] = languages[filedata[i][j]]\n",
    "        elif (j == 6):\n",
    "            data[i][j] = religions[filedata[i][j]]\n",
    "        else:\n",
    "            data[i][j] = filedata[i][j]\n",
    "        # Make the row into a numpy array\n",
    "        data[i] = np.array(data[i])\n",
    "\n",
    "# Transpose so that features are along the rows and data points are along the columns\n",
    "data = np.array(data).transpose()\n",
    "\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Dataset\n",
    "The point of this problem is to only use the data and features that we can get from a given countries flag. This dataset includes features such as population, density etc. that are not related to the flag, and should be removed.\n",
    "One of these, religion, will be our label that we are aiming to predict based off of the flag. Thus we will have to extract the religion feature as a label, and eliminate the non-flag related features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Afghanistan' 'Albania' 'Algeria' ... 'Zaire' 'Zambia' 'Zimbabwe']\n",
      " ['Asia' 'Europe' 'Africa' ... 'Africa' 'Africa' 'Africa']\n",
      " ['NE' 'NE' 'NE' ... 'SE' 'SE' 'SE']\n",
      " [648 29 2388 ... 905 753 391]\n",
      " [16 3 20 ... 28 6 8]\n",
      " ['Others' 'Other Indo-European' 'Arabic' ... 'Others' 'Others' 'Others']]\n"
     ]
    }
   ],
   "source": [
    "# Extract the religions as the labels, row 6\n",
    "names = data[0]\n",
    "labels = data[6] \n",
    "data = np.delete(data, 6, axis=0)\n",
    "\n",
    "# Extract the non flag related data\n",
    "print (data[0:6])\n",
    "for i in range(6):\n",
    "    data = np.delete(data, 0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing our Cleaned Data\n",
    "\n",
    "With our data cleaned and prepared for analysis, we can start our analysis. Our goal is to build a classifier that based on these features about a country's flag, we can classify that country's major religion. It may be interesting to see what would happen if we used another feature as a target, but for this project we will be solely be focused on a classifier that focuses on religion.\n",
    "These are the 3 methods that will be used, along with the group member responsible for that method:\n",
    "- K-Nearest Neighbors - Brooks Tawil\n",
    "- Naive Bayes - Jack Chiu\n",
    "- Kernal SVM - Gavin Mckim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors - Brooks Tawil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 23)\n",
      "[[0 3 5 ... 0 0 0]\n",
      " [0 0 3 ... 0 1 1]\n",
      " [2 0 3 ... 0 2 2]\n",
      " ...\n",
      " [0 0 4 ... 0 2 0]\n",
      " [3 0 4 ... 0 2 7]\n",
      " [0 7 5 ... 0 2 0]]\n",
      "['Muslim' 'Marxist' 'Other Christian' 'Catholic' 'Ethnic' 'Buddhist'\n",
      " 'Hindu' 'Others']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def uNiQuE(vec):\n",
    "    popCtr = 0\n",
    "    for p in vec:\n",
    "        if p in vec[:popCtr]:\n",
    "            vec = np.delete(vec, popCtr, 0)\n",
    "            popCtr -= 1\n",
    "        popCtr += 1\n",
    "        \n",
    "    return vec \n",
    "\n",
    "def preProcess(data):\n",
    "    i = 0\n",
    "    for q in range(len(data)):\n",
    "        if None in data[i]:\n",
    "            data = np.delete(data, i, 0)\n",
    "            i -= 1        \n",
    "        i += 1\n",
    "        for j in range(len(data[i-1])):\n",
    "            if type(data[i-1,j]) == str:\n",
    "                data[i-1,j] = data[i-1,j].lower()\n",
    "\n",
    "    domColor = uNiQuE(data[:,10])\n",
    "    topLeftColor = uNiQuE(data[:,-2])\n",
    "    botRightColor = uNiQuE(data[:,-1])\n",
    "    numStars = np.array([6, 5, 4, 3, 2, 1, 0])\n",
    "    for i in range(len(data)):\n",
    "        tempInd = np.where(domColor == data[i,10])\n",
    "        data[i,10] = int(tempInd[0])\n",
    "        tempInd = np.where(topLeftColor == data[i,-2])\n",
    "        data[i,-2] = int(tempInd[0])\n",
    "        tempInd = np.where(botRightColor == data[i,-1])\n",
    "        data[i,-1] = int(tempInd[0])\n",
    "        \n",
    "        #make stars be in range [0 to >5]\n",
    "        tempInd = np.where(numStars <= data[i,15])\n",
    "        data[i,15] = int(tempInd[0][0])\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            data[i,j] = int(data[i,j])\n",
    "    return data\n",
    "\n",
    "cleanData = preProcess(data.T)\n",
    "religions = uNiQuE(labels)\n",
    "\n",
    "print (cleanData.shape)\n",
    "print (cleanData)\n",
    "print (religions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Euclidean Distance as the distance metric. other distance metrics, such as Manhattan Distance, do exist and could also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(trainingInstance, testInstance, length):\n",
    "    distance = 0.0    \n",
    "    for x in range(length):\n",
    "        distance += np.square(trainingInstance[x] - testInstance[x])\n",
    "    \n",
    "    return math.sqrt(distance)\n",
    "\n",
    "# Defining our KNN model\n",
    "def knn(trainingSet, testInstance, k):\n",
    "    # The training set will have the labels appended to the end, so that sorting can be done with the labels attached\n",
    "    distances = {}\n",
    "    sort = {}\n",
    " \n",
    "    length = len(testInstance)\n",
    "    \n",
    "    # Calculating euclidean distance between each row of training data and test data\n",
    "    for x in range(len(trainingSet)):\n",
    "        distances[x] = euclideanDistance(trainingSet[x], testInstance.T, length)\n",
    "          \n",
    "    # Sorting them on the basis of distance\n",
    "    sorted_d = sorted(distances.items(), key=operator.itemgetter(1))\n",
    " \n",
    "    # Extracting top k neighbors\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(sorted_d[x])\n",
    "    classVotes = {}\n",
    "    \n",
    "    # Calculating the most freq class in the neighbors\n",
    "    for x in range(len(neighbors)):\n",
    "        response = trainingSet[neighbors[x][0]][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    # Return as tuple (Class, List Of Neighbors)\n",
    "    return(sortedVotes[0][0], neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross Validation\n",
    "\n",
    "For this dataset, we don't have that many country flags to use. We only have 194 country flags to work with! In addition, the use of kNN means that we especially want to have a large training set, so that our distances between our training and test instances are not that far from the expected reality, with holes in our training. In addition, our dataset is relatively small, so with a modern system the computation will not take long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136, 136, 120, 115, 112, 114, 110, 114, 114, 115, 114]\n",
      "[58, 58, 74, 79, 82, 80, 84, 80, 80, 79, 80]\n",
      "[0.29896907216494845, 0.29896907216494845, 0.38144329896907214, 0.4072164948453608, 0.422680412371134, 0.41237113402061853, 0.4329896907216495, 0.41237113402061853, 0.41237113402061853, 0.4072164948453608, 0.41237113402061853]\n",
      "Best K:  7\n"
     ]
    }
   ],
   "source": [
    "# Run KNN with Leave-One-Out Cross Validation\n",
    "kRange = range(1, 12)\n",
    "missClasses = [0 for _ in range(len(kRange))]\n",
    "correctClasses = [0 for _ in range(len(kRange))]\n",
    "accuracies = [0 for _ in range(len(kRange))]\n",
    "\n",
    "# Leave-One-Out CV, changing the k in kNN\n",
    "for k in kRange:\n",
    "    for i in range(len(cleanData)):\n",
    "        # Remake our dataWithLabels\n",
    "        dataWithLabels = list(cleanData.T)\n",
    "        np.array(dataWithLabels.append(labels.T))\n",
    "        dataWithLabels = np.array(dataWithLabels).T\n",
    "        \n",
    "        # Assign a single test instance\n",
    "        testInstance = cleanData[i-1]\n",
    "        testInstanceLabel = labels[i-1]\n",
    "\n",
    "        # We will only delete from dataWithLabels\n",
    "        dataWithLabels = np.delete(dataWithLabels, i-1, axis=0)\n",
    "        \n",
    "        # Run knn\n",
    "        assignment, neighbors = knn(dataWithLabels, testInstance, k)\n",
    "        \n",
    "        # Check if the assignemnt is correct\n",
    "        if (assignment == testInstanceLabel):\n",
    "            correctClasses[k-1] += 1\n",
    "        else:\n",
    "            missClasses[k-1] += 1\n",
    "\n",
    "print (missClasses)\n",
    "print (correctClasses)\n",
    "\n",
    "# Compute the accuracies for each fold and report\n",
    "for i in range(len(accuracies)):\n",
    "    accuracies[i] = correctClasses[i]/float(correctClasses[i] + missClasses[i])\n",
    "    \n",
    "print (accuracies)\n",
    "best_k = list(kRange)[np.argmax(accuracies)]\n",
    "\n",
    "print ('Best K: ', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example run for  Denmark\n",
      "Denmark has a majority religion of:  Other Christian\n",
      "Denmark has been successfully classified as:  Other Christian\n",
      "[(45, 0.0), (165, 0.0), (129, 1.4142135623730951), (174, 1.7320508075688772), (91, 2.0), (105, 2.0), (116, 2.0)]\n",
      "Similar countries are:\n",
      "Czechoslovakia\n",
      "Sweden\n",
      "North-Yemen\n",
      "Tunisia\n",
      "Jordan\n",
      "Malaysia\n",
      "Montserrat\n"
     ]
    }
   ],
   "source": [
    "# Example for a single run with  as the single testing point \n",
    "print ('Example run for ', names[46])\n",
    "\n",
    "# Remake our dataWithLabels\n",
    "dataWithLabels = list(cleanData.T)\n",
    "np.array(dataWithLabels.append(labels.T))\n",
    "dataWithLabels = np.array(dataWithLabels).T\n",
    "\n",
    "# Assign a single test instance\n",
    "testInstance = cleanData[46]\n",
    "testInstanceLabel = labels[46]\n",
    "\n",
    "print ('Denmark has a majority religion of: ', testInstanceLabel)\n",
    "\n",
    "# We will only delete from dataWithLabels\n",
    "dataWithLabels = np.delete(dataWithLabels, i-1, axis=0)\n",
    "\n",
    "# Run knn\n",
    "assignment, neighbors = knn(dataWithLabels, testInstance, best_k)\n",
    "\n",
    "# Check if the assignemnt is correct\n",
    "if (assignment == testInstanceLabel):\n",
    "    print ('Denmark has been successfully classified as: ', testInstanceLabel)\n",
    "else:\n",
    "    print ('Denmark has been unsuccessfully classified as: ', assignment, ' when it is actually: ', testInstanceLabel)\n",
    "    \n",
    "print (neighbors)\n",
    "print ('Similar countries are:')\n",
    "# Print the neighbors\n",
    "for i in range(len(neighbors)):\n",
    "    print (names[neighbors[i][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Ultimately this classifier does not reach an accuracy beyond 45%. Using the KNN algorithm we were expecting better results. Howvever, when looking at a run against a single country, and then looking at samples of flags, its no surprise that the accuracy is that low for this particiular algorithm. Countries often share characteristics like color across a wide range of symbols and meaning, not necessarily religious. There does not appear to be a string linke between most country's flags and the majority religion. In addition, there is room for confusion caused differentiating countries across certain religious lines. For example there are a lot of similarities between countries labeled as 'Catholic' and 'Other Christian' but an incorrect classification may still be reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Jack Chiu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  3  with average accuracy =  0.201389\n",
      "Accuracy for each fold:  [0.203125, 0.234375, 0.166667]\n",
      "k =  5  with average accuracy =  0.275689\n",
      "Accuracy for each fold:  [0.184211, 0.210526, 0.263158, 0.315789, 0.404762]\n",
      "k =  7  with average accuracy =  0.304729\n",
      "Accuracy for each fold:  [0.185185, 0.37037, 0.407407, 0.222222, 0.407407, 0.259259, 0.28125]\n",
      "k =  9  with average accuracy =  0.275336\n",
      "Accuracy for each fold:  [0.190476, 0.333333, 0.333333, 0.380952, 0.142857, 0.142857, 0.428571, 0.333333, 0.192308]\n",
      "k =  11  with average accuracy =  0.36943\n",
      "Accuracy for each fold:  [0.411765, 0.470588, 0.235294, 0.294118, 0.294118, 0.529412, 0.352941, 0.294118, 0.588235, 0.176471, 0.416667]\n"
     ]
    }
   ],
   "source": [
    "def uNiQuE(vec):\n",
    "    popCtr = 0\n",
    "    for p in vec:\n",
    "        if p in vec[:popCtr]:\n",
    "            vec = np.delete(vec, popCtr, 0)\n",
    "            popCtr -= 1\n",
    "        popCtr += 1\n",
    "        \n",
    "    return vec   \n",
    "\n",
    "def kFold(data, labels, kFolds):\n",
    "    #shuffle\n",
    "    inds = np.random.choice(np.arange(len(data)), len(data))\n",
    "    data[:] = data[inds]\n",
    "    labels[:] = labels[inds]\n",
    "\n",
    "    startInd = 0\n",
    "    stepSize = int(len(data)/kFolds)\n",
    "    Acc = []\n",
    "    predictions = []\n",
    "    for i in range(kFolds):\n",
    "        if i != kFolds-1:\n",
    "            testData = data[startInd:startInd+stepSize]\n",
    "            testLabels = labels[startInd:startInd+stepSize]\n",
    "            trainingData = data[:startInd]\n",
    "            trainingData = np.concatenate((trainingData, data[startInd+stepSize:]))\n",
    "            trainingLabels = labels[:startInd]\n",
    "            trainingLabels = np.concatenate((trainingLabels,labels[startInd+stepSize:]))\n",
    "        else:\n",
    "            testData = data[startInd:]\n",
    "            testLabels = labels[startInd:]\n",
    "            trainingData = data[:startInd]\n",
    "            trainingLabels = labels[:startInd]\n",
    "\n",
    "        startInd += stepSize\n",
    "        temp, pList = calcErrNaive(trainingData, trainingLabels, testData, testLabels)\n",
    "        Acc.append(temp)\n",
    "        predictions.extend(pList)\n",
    "    \n",
    "    return Acc, labels, predictions\n",
    "        \n",
    "\n",
    "def trainNaive(data, labels):\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    prior = counts\n",
    "    prior = (prior+0.0)/len(data)\n",
    "    \n",
    "    conditional = np.zeros((8, len(data[0]), 50))\n",
    "    #conditional = (labels, feature, values in feature)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            conditional[labels[i], j, data[i,j]] += 1\n",
    "    for i in range(len(conditional)):\n",
    "        for j in range(len(conditional[0])):\n",
    "            sumCondition = 0\n",
    "            for k in range(0,conditional.shape[0]):\n",
    "                sumCondition += sum(conditional[k,j,:])\n",
    "            for k in range(0,len(conditional[0,j])):\n",
    "                conditional[i,j,k] = conditional[i,j,k]/sumCondition\n",
    "    \n",
    "\n",
    "    return prior, conditional, unique\n",
    "\n",
    "\n",
    "def testNaive(prior, conditional, unique, sample):\n",
    "    prob = prior\n",
    "    for i in range(len(sample)):\n",
    "        for j in range(len(prob)):\n",
    "            prob[j] = prob[j] * conditional[j,i,sample[i]]\n",
    "    maxVal = np.argmax(prob)\n",
    "        \n",
    "    return unique[maxVal]\n",
    "        \n",
    "def calcErrNaive(trainingData, trainingLabels, testData, testLabels):\n",
    "    errs = 0\n",
    "    prior, conditional, unique = trainNaive(trainingData, trainingLabels)\n",
    "    pList = []\n",
    "    for i in range(len(testData)):\n",
    "        prediction = testNaive(prior, conditional, unique, testData[i])\n",
    "        errs += int(prediction == testLabels[i])\n",
    "        pList.append(prediction)\n",
    "        \n",
    "    return np.round(errs/len(testLabels), 6), pList\n",
    "\n",
    "\n",
    "def preProcess(data):\n",
    "    i = 0\n",
    "    for q in range(len(data)):\n",
    "        if None in data[i]:\n",
    "            data = np.delete(data, i, 0)\n",
    "            i -= 1        \n",
    "        i += 1\n",
    "        for j in range(len(data[i-1])):\n",
    "            if type(data[i-1,j]) == str:\n",
    "                data[i-1,j] = data[i-1,j].lower()\n",
    "\n",
    "    domColor = uNiQuE(data[:,10])\n",
    "    topLeftColor = uNiQuE(data[:,-2])\n",
    "    botRightColor = uNiQuE(data[:,-1])\n",
    "    numStars = np.array([6, 5, 4, 3, 2, 1, 0])\n",
    "    for i in range(len(data)):\n",
    "        tempInd = np.where(domColor == data[i,10])\n",
    "        data[i,10] = int(tempInd[0])\n",
    "        tempInd = np.where(topLeftColor == data[i,-2])\n",
    "        data[i,-2] = int(tempInd[0])\n",
    "        tempInd = np.where(botRightColor == data[i,-1])\n",
    "        data[i,-1] = int(tempInd[0])\n",
    "        \n",
    "        #make stars be in range [0 to >5]\n",
    "        tempInd = np.where(numStars <= data[i,15])\n",
    "        data[i,15] = int(tempInd[0][0])\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            data[i,j] = int(data[i,j])\n",
    "    return data\n",
    "\n",
    "tempData = preProcess(data.T)\n",
    "religions = uNiQuE(labels)\n",
    "tempLabels = labels[:]\n",
    "for i in range(len(labels)):\n",
    "    tempInd = np.where(religions == labels[i])\n",
    "    tempLabels[i] = int(tempInd[0])\n",
    "    \n",
    "for i in np.arange(3,13,2):\n",
    "    acc, actual, predictions = kFold(tempData, tempLabels, i)\n",
    "    print('k = ', i, ' with average accuracy = ' , np.average(acc).round(6))\n",
    "    print('Accuracy for each fold: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes was created to classify from the data what type of religion the country with that flag would have. Evidently, from running the classifier with k-fold cross validation over various k values, the accuracy of the classifier was pretty low $\\leq 40\\%$. It can be said that there is a pretty weak relation between the country's flag features/data and the majority religion of that country based on the Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Religions and Predicted Religion for first 20 samples: \n",
      "Actual:  Buddhist \t \t Predicted: Catholic\n",
      "Actual:  Muslim \t \t Predicted: Catholic\n",
      "Actual:  Ethnic \t \t Predicted: Muslim\n",
      "Actual:  Muslim \t \t Predicted: Muslim\n",
      "Actual:  Other Christian \t Predicted: Muslim\n",
      "Actual:  Muslim \t \t Predicted: Muslim\n",
      "Actual:  Muslim \t \t Predicted: Muslim\n",
      "Actual:  Other Christian \t Predicted: Muslim\n",
      "Actual:  Catholic \t \t Predicted: Muslim\n",
      "Actual:  Muslim \t \t Predicted: Muslim\n",
      "Actual:  Muslim \t \t Predicted: Muslim\n",
      "Actual:  Buddhist \t \t Predicted: Muslim\n",
      "Actual:  Muslim \t \t Predicted: Muslim\n",
      "Actual:  Muslim \t \t Predicted: Muslim\n",
      "Actual:  Other Christian \t Predicted: Muslim\n",
      "Actual:  Buddhist \t \t Predicted: Muslim\n",
      "Actual:  Other Christian \t Predicted: Muslim\n",
      "Actual:  Muslim \t \t Predicted: Muslim\n",
      "Actual:  Catholic \t \t Predicted: Other Christian\n",
      "Actual:  Ethnic \t \t Predicted: Muslim\n"
     ]
    }
   ],
   "source": [
    "acc, actual, predictions = kFold(tempData, tempLabels, 11)\n",
    "print('Actual Religions and Predicted Religion for first 20 samples: ')\n",
    "for i in range(20):\n",
    "    if actual[i] == 2:\n",
    "        print('Actual: ', religions[actual[i]], '\\t Predicted:', religions[predictions[i]])\n",
    "    elif actual[i] == 6:\n",
    "        print('Actual: ', religions[actual[i]], '\\t \\t \\t Predicted:', religions[predictions[i]])\n",
    "    else:\n",
    "        print('Actual: ', religions[actual[i]], '\\t \\t Predicted:', religions[predictions[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Naive Bayes Classifier, the classifier tends to classify the flags as majority Muslim religion. Thus, based on Naive Bayes, there seems to not be much relation between a flag's image and its country's religion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernal SVM - Gavin McKim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "sdata = data[0:21,:]\n",
    "sdata = np.delete(sdata, 10, 0)\n",
    "#Following the preprocessing done by Brooks, I did a little of my own preprocessing. I just got rid of all the features\n",
    "# that don't have numerical values.\n",
    "\n",
    "#print(np.shape(sdata))\n",
    "#print(sdata)\n",
    "shfl = np.vstack((sdata,np.reshape(labels,[1,194])))\n",
    "shfl = np.random.permutation(shfl.T).T\n",
    "sdata = shfl[0:20,:]\n",
    "labels = shfl[20,:]\n",
    "\n",
    "#print(shfl)\n",
    "\n",
    "\n",
    "#print(sdata[8,:])\n",
    "G = np.arange(.01,1,0.01)\n",
    "\n",
    "#for c in C:\n",
    "means = []\n",
    "for g in G:\n",
    "    #The Kernel used is Radia Bias Kernel. I have a loop to find the optimal value of the tuning parameter G(or gamma in\n",
    "    # the SVC call. I have decided to not tune the penalty parameter C because it makes the runtime too long on my computer).\n",
    "    clf = svm.SVC(C=1, kernel='rbf', gamma=g)\n",
    "\n",
    "    acc = []\n",
    "\n",
    "\n",
    "    # 5-Fold Cross Validation\n",
    "    for i in range(5):\n",
    "        if i == 0:\n",
    "            testing = sdata[:,0:39]\n",
    "            training = sdata[:,39:194]\n",
    "            yf = labels[39:194]\n",
    "            yt = labels[0:39]\n",
    "        if i == 1:\n",
    "            testing = sdata[:,39:78]\n",
    "            training = np.concatenate((sdata[:,0:39],sdata[:,78:194]), axis=1)\n",
    "            yf = np.concatenate((labels[0:39],labels[78:194]), axis=0)\n",
    "            yt = labels[39:78]\n",
    "        if i == 2:\n",
    "            testing = sdata[:,78:117]\n",
    "            training = np.concatenate((sdata[:,0:78],sdata[:,117:194]), axis=1)\n",
    "            yf = np.concatenate((labels[0:78],labels[117:194]), axis=0)\n",
    "            yt = labels[78:117]\n",
    "        if i == 3:\n",
    "            testing = sdata[:,117:156]\n",
    "            training = np.concatenate((sdata[:,0:117],sdata[:,156:194]), axis=1)\n",
    "            yf = np.concatenate((labels[0:117],labels[156:194]), axis=0)\n",
    "            yt = labels[117:156]\n",
    "        if i == 4:\n",
    "            testing = sdata[:,156:194]\n",
    "            training = sdata[:,0:156]\n",
    "            yf = labels[0:156]\n",
    "            yt = labels[156:194]\n",
    "\n",
    "        clf.fit(training.T, yf)\n",
    "        acc.append(clf.score(testing.T,yt))\n",
    "    means.append(np.mean(acc))\n",
    "\n",
    "opt = np.argmax(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy is: 0.3137651821862348\n",
      "This accuracy is achieved by having a gamma term of: 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"The highest accuracy is:\",means[opt])\n",
    "print(\"This accuracy is achieved by having a gamma term of:\", (opt/100)+.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
